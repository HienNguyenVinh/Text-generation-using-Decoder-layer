# Vietnamese text generation model using Decoder layer from Transformer architecture
**This model using data from 2000 blogs on web Spiderum to train**

This model have this parameters:
  - vocab_size
  - num_layers 
  - d_model
  - num_heads 
  - ff_dim 
  - seq_len 
  - dropout_rate 
  - batch_size 

You can download this project and train your model using this line in your terminal:
  python train.py --batch-size 64 --vocab-size 10000 ...   
